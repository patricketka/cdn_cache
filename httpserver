#!/usr/bin/env python3
import http.server
import http.client
import os
import csv
import sys
import argparse
import threading
from socketserver import BaseRequestHandler
from typing import Tuple, Callable


class handler(http.server.BaseHTTPRequestHandler):

    def do_GET(self):
        if self.path == '/grading/beacon':
            self.send_response(204)
            self.end_headers()
        elif self.path == '/kill':
            self.send_response(200)
            self.end_headers()
            raise sys.exit()
        else:
            code, response = self.__getattribute__('server').retrieve_file(self.path)
            self.send_response(code)
            self.end_headers()
            if code == 200:
                self.wfile.write(bytes(response.replace('\\n', '').replace('\\t', ''), 'utf-8'))


class server(http.server.HTTPServer):

    def __init__(self, serverName, port, server_address: Tuple[str, int],
                 RequestHandlerClass: Callable[..., BaseRequestHandler]):
        self.origin_connection = http.client.HTTPConnection(serverName, port)
        self.cache = {}
        super().__init__(server_address, RequestHandlerClass)

    def retrieve_file(self, path):
        if path in self.cache.keys():
            return 200, self.cache[path]
        else:
            # chunks = pandas.read_csv('secondary_cache.csv', chunksize=1)
            # for chunk in chunks:
            #     print(chunk)
            self.origin_connection.request('GET', path)
            response = self.origin_connection.getresponse()
            code = response.getcode()
            response = str(response.read()[2:-1])
            return code, response

    def set_up_cache(self):
        with open('cache.csv', 'r') as cache_file:
            i = 0
            csv.field_size_limit(20000000)
            csv_file = csv.reader(cache_file)
            for row in csv_file:
                if len(row):
                    i += 1
                    self.cache[row[0]] = row[1][:-1]
        os.system('rm cache.csv')

        '''
        Below code used to create cache.csv file and ensure it was not above 20MB
        '''
        # CACHE_SIZE = 0
        # with open('pageviews.csv', 'r', errors='ignore') as wiki_views:
        #     page_views = wiki_views.readlines()
        #     i = 0
        #     with open('cache.csv', 'w') as cache:
        #         writer = csv.writer(cache)
        #         while 1:
        #             path = '/' + page_views[i].split(',')[0]
        #             self.origin_connection.request('GET', path)
        #             page_response = str(self.origin_connection.getresponse().read())
        #             page_response = page_response.replace('\n', '')
        #             CACHE_SIZE += (sys.getsizeof(page_response) + sys.getsizeof(path))
        #             if CACHE_SIZE < 20000000:
        #                 self.cache[path] = page_response[2:-1]
        #                 i += 1
        #                 print(i)
        #                 writer.writerow([path, page_response[2:-1]])
        #             else:
        #                 CACHE_SIZE -= (sys.getsizeof(page_response) + sys.getsizeof(path))
        #                 break

        # print(CACHE_SIZE)
        # os.system('rm pageviews.csv')
        # with open('secondary_cache.csv', 'w') as secondary_cache:
        #     writer = csv.writer(secondary_cache)
        #     for i in range(10):
        #         path = '/' + page_views[i].split(',')[0]
        #         self.origin_connection.request('GET', path)
        #         page_response = self.origin_connection.getresponse().read()
        #         data = [path, page_response]
        #         writer.writerow(data)


def deploy_cache(server_instance):
    server_instance.set_up_cache()


def start_server(server_instance):
    try:
        server_instance.serve_forever()
    except ValueError:
        pass


def parse_arguments():
    """Parse the command line arguments to determine how program should run
    :return: A list of arguments passed in through the command line
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('-p', type=str, required=True)
    parser.add_argument('-o', type=str, required=True)
    return parser.parse_args()


def main():
    threads = []
    args = parse_arguments()
    port_number = int(args.p)
    origin_server = args.o
    my_server = server(origin_server, 8080, ('', port_number), handler)
    deploy_cache_thread = threading.Thread(target=deploy_cache(my_server))
    threads.append(deploy_cache_thread)
    server_listen_thread = threading.Thread(target=start_server(my_server))
    threads.append(server_listen_thread)
    for thread in threads:
        thread.join()
    my_server.server_close()


main()
